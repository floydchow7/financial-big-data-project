{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to extract the needed data for the further analysis in this project. Import the extraction function from the `utils.data_extractor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\floyd\\.conda\\envs\\big_data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.data_extractor import *\n",
    "from utils.helpers import write_file\n",
    "from utils.constants import Constant\n",
    "import pandas as pd\n",
    "C = Constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract TSLA News from the FNSPID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA is saved to: C:/Users/floyd/Desktop/financial-big-data-project/data/raw//TSLA_news.parquet\n"
     ]
    }
   ],
   "source": [
    "# Select the tickers to be used in the analysis\n",
    "ticker_list = [\"TSLA\"]\n",
    "\n",
    "#Applying the function (can extract as many tickers you like)\n",
    "filter_and_save_parquet(input_path = C.FNSPID_data_path, ticker_list = ticker_list, output_folder = C.raw_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract TSLA Price from yahoofinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\floyd\\.conda\\envs\\big_data\\Lib\\site-packages\\yfinance\\utils.py:771: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "start_date = \"2019-07-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "ticker_symbol = \"TSLA\"\n",
    "tesla_stock_data = get_stock_price_data(ticker_symbol,start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess and writing the Tesla Quotes\n",
    "tesla_stock_data = tesla_stock_data.filter([\"Date\",\"Close\"])\n",
    "tesla_stock_data[\"Date\"] = tesla_stock_data[\"Date\"].apply(lambda val:pd.to_datetime(val))\n",
    "\n",
    "#Writing the file\n",
    "write_file(tesla_stock_data,f\"{C.clean_data_dir}tesla_quotes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract Elon Musk's Tweets from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/gpreda/elon-musk-tweets?dataset_version_number=336...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 369k/369k [00:00<00:00, 911kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Downloaded dataset to: C:\\Users\\floyd\\.cache\\kagglehub\\datasets\\gpreda\\elon-musk-tweets\\versions\\336\n",
      "File moved to: C:/Users/floyd/Desktop/financial-big-data-project/data/raw/elon_musk_tweets.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_musk_tweets_data(destination_folder = C.raw_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract dogecoin data from Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "df_doge = fetch_coin_data_from_binance(\n",
    "    api_key=C.API_KEY,\n",
    "    api_secret=C.API_SECRET,\n",
    "    start_date=\"4 Nov, 2021\", #cutoff value for the TSLA stock\n",
    "    end_date=\"31 Dec, 2023\",\n",
    "    symbol=\"DOGEUSDT\",\n",
    "    interval=\"1m\"\n",
    ")\n",
    "#Preprocess the Dogecoin price data\n",
    "df_doge = (\n",
    "            df_doge.filter([\"time_open\", \"Close\"])\n",
    "                  .rename({\"time_open\":\"Date\"}, axis = 1)\n",
    "                  )\n",
    "\n",
    "df_doge[\"Date\"] = df_doge[\"Date\"].apply(lambda val: pd.to_datetime(val))\n",
    "write_file(df_doge, f\"{C.clean_data_dir}doge_price.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract Crypto News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/oliviervha/crypto-news?dataset_version_number=10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.99M/3.99M [00:00<00:00, 4.74MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Downloaded dataset to: C:\\Users\\floyd\\.cache\\kagglehub\\datasets\\oliviervha\\crypto-news\\versions\\10\n",
      "File moved to: C:/Users/floyd/Desktop/financial-big-data-project/data/raw/crypto_news.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_crypto_news_data(destination_folder = C.raw_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
